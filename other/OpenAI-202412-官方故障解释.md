# 202412 OpenAI 服务故障 官方解释

20241211 OpenAI 经历了一次服务故障，OpenAI 给出了详细的解释和预防方案。下面是我阅读的分析，和部分解读。

https://status.openai.com/incidents/ctrsv3lwd797

整体看，原因是他们发布了一个 telemetry 应用，但是由于配置问题和对压力的评估不足，导致了 k8s 集群的控制面服务器压力过大，进而拖垮了他们全球的所有的控制面服务器。

按理说，服务一般运行在数据面，控制面与数据面是分离的，控制面失效不会影响到数据面。但是控制面有个关键的 DNS 发现服务，数据面服务依靠它来实现，数据面服务之间的互相调用。这个服务挂了，导致数据面服务也不能正常运转。

虽然DNS 服务不可用了，但是依然有 20 分钟的缓存，所以用户不是马上感知到故障。OpenAI 本来可以利用这个时间及时回滚服务，他们也表示他们有相关工具实现这一点（we have tools to detect and roll back bad deployments.）。但是控制面此刻已经满载，导致运维人员无法进入控制面操作。（文章总结这种情况为 the locked out effect.）

OpenAI  团队采取以下三种措施同步进行，对问题进行修复

- Scaling down cluster size 减少 telemetry 应用带来的压力。
- Blocking network access to Kubernetes admin APIs 同上，也是为了减低压力
- Scaling up Kubernetes API servers 提升控制面的资源水平，使得有足够资源执行修复操作。

事故后团队采取以下措施防止类似的事故

- Robust phased rollouts. 分阶段发布，不要一次性投上去，就像上次微软那次蓝屏事件那样。使用 better monitoring for all infrastructure 确保资源都是 healthy 再发布。
- Fault injection testing. 团队将专门测试控制面故障的情况，保证数据面能够正常运作。并且，团队将专门测试发布 bad changes，确保系统能够正常检测到故障并有效恢复。
- Emergency Kubernetes control plane access. 采取措施（break-glass mechanisms），确保工程师在任何情况下都能正常访问控制面。
- Decouple the Kubernetes data plane and control plane. 控制面和数据面实现解耦，不要让控制面承担关键服务（ritical services and product workloads.）。
- Faster recovery. 提升 caching and dynamic rate limiters，并且进行有计划的日常演练，实现更快的故障恢复。

## 名词解释

### fleet 如何理解

> This event was the result of an internal change to roll out new telemetry across our fleet and was not caused by a security incident or a recent launch. 

fleet 是指 OpenAI 公司，所有的服务，包括服务器、节点、部署的各种服务等。这句话，说的就是 OpenAI 要在他们的整个系统上部署上线新的 telemetry 系统。

我们写英文文章，可以用 fleet 这个单词，表示某个大系统的所有内容。

### 什么是 model inference

> OpenAI operates hundreds of Kubernetes clusters globally. Kubernetes has a control plane responsible for cluster administration and a data plane from where we actually serve workloads like model inference.

模型推理。机器学习术语，是指训练完的模型，后续用于实际推理的过程。向模型输入数据，模型输出对应内容，这个过程就是 model inference。

来自 ChatGPT 的回答: 

这里的 model inference 指的是在机器学习或深度学习模型训练完成后，将训练好的模型部署并用于实际推理任务的过程。在这种情况下，模型接收新的输入数据并生成预测或输出结果。

在 OpenAI 的上下文中，model inference 可能指以下几种典型任务：

1. 语言模型推理：比如 ChatGPT 接收到用户输入的文本，并实时生成回复。
2. 图像生成推理：如使用 DALL-E 模型根据输入的描述生成图像。
3. 语音识别或合成：接收音频数据并生成文本或音频输出。

### scaled with 表示“随着……而变化”

> Telemetry services have a very wide footprint, so this new service’s configuration unintentionally caused every node in each cluster to execute resource-intensive Kubernetes API operations whose cost scaled with the size of the cluster. 

随着集群规模的变大，resource-intensive Kubernetes API operations 的带来的压力也会越大。

### Break-glass mechanisms 如何理解

> We’ll implement break-glass mechanisms to ensure that engineers can access Kubernetes API servers in any circumstances.

“Break-glass mechanisms”（破玻璃机制）是一种紧急访问控制策略，类似于在紧急情况下打破玻璃来获取安全设备（如灭火器或紧急钥匙）。在 IT 和系统运维中，它指的是在紧急或特殊情况下绕过常规安全措施的机制，确保工程师或管理员能够在任何情况下访问关键系统或服务。

### 其他

| **词**       | **中文意思**           |
|--------------------|------------------------|
| mitigate           | 减轻，缓解             |
| tune on            | 调整，使适应           |
| precaution         | 预防措施，防范         |
| spin up            | 启动，快速创建         |
| remediation        | 补救，修正             |
| manual intervention| 手动干预               |
| circumstance       | 情况，情形             |
| fall short of      | 未达到，不足           |
| prioritize         | 优先考虑，优先处理     |
| postmortem         | 事后分析，事后总结     |



